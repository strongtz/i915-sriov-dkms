This repo packages an i915/xe kernel driver tree with SR-IOV support as a DKMS
module. It includes both the classic i915 driver and the newer xe driver, plus
build and distro packaging helpers.

High-level layout
- drivers/gpu/drm/i915: i915 driver with SR-IOV extensions.
- drivers/gpu/drm/xe: xe driver (newer Intel GPU driver) with SR-IOV support.
- include/: driver headers and uapi bits.
- compat/, dkms.conf, PKGBUILD, debian/: DKMS and packaging glue.

SR-IOV in i915
- Core SR-IOV logic lives under drivers/gpu/drm/i915/gt/iov/ and the
  i915_sriov*.c helpers. This handles PF/VF provisioning, GGTT updates,
  relay/messaging, and migration state save/restore.
- GVT (mediated vGPU) plumbing is also present under drivers/gpu/drm/i915/gvt/.
  This includes a dma-buf export path for vGPU framebuffer planes in
  drivers/gpu/drm/i915/gvt/dmabuf.c.

SR-IOV in xe
- SR-IOV support is spread across xe_sriov*.c, xe_gt_sriov_*.c, and
  xe_tile_sriov_*.c files (PF/VF control, provisioning, migration, and debugfs).
- The xe driver has its own dma-buf support (drivers/gpu/drm/xe/xe_dma_buf.c)
  and BO/VM helpers that handle imported/exported dma-bufs in general.

Looking Glass / KVMFR zero-copy note
- There are no references to KVMFR or Looking Glass in this tree.
- Any zero-copy behavior for Looking Glass is not implemented as a dedicated
  driver feature here; it relies on generic dma-buf support and the KVMFR
  module/userspace stack rather than SR-IOV-specific code in this repo.

Key files touched for dma-buf and vGPU
- i915: drivers/gpu/drm/i915/gem/i915_gem_dmabuf.c
- i915 GVT: drivers/gpu/drm/i915/gvt/dmabuf.c
- xe: drivers/gpu/drm/xe/xe_dma_buf.c

Recent SR-IOV / MMIO relay learnings
- GuC forwards VF MMIO relay requests to PF as G2H action 0x5006; the PF must
  decode opcodes and reply via PF2GUC success/failure messages.
- The relay is used by Windows VF drivers for ABI handshake, runtime register
  reads, and VF GGTT PTE updates; missing support causes Code 43 or boot issues.
- xe now mirrors i915 behavior by handling handshake/get-runtime/update-GGTT
  in drivers/gpu/drm/xe/xe_guc_ct.c and updating PTEs in the VF GGTT slice via
  drivers/gpu/drm/xe/xe_ggtt.c with VFID tagging and GGTT invalidation.

MTL SR-IOV platform notes
- MTL appears to require SR-IOV enablement in xe plus PF-side GSC/PXP gating
  around VF transitions; this aligns xe behavior with i915 SR-IOV expectations.
- For multi-GT parts (like MTL), PF FLR dispatch must run on more than just PVC;
  the xe PF FLR dispatch path should consider gt_count > 1.

Recent debugging / fixes
- The VF GGTT MMIO relay path could deadlock: G2H worker held ggtt->lock and
  called xe_tlb_inval_ggtt (GuC CT send), causing lock inversion with other
  GGTT/TTM users and hung-task reports.
- Fix: defer GGTT invalidation to a work item on the GGTT workqueue after
  releasing ggtt->lock; coalesce invalidations with a pending flag and run
  under PM runtime to ensure the device is powered during invalidate.
- Added VF2PF_UPDATE_GGTT32 relay support in xe PF: parse relay requests,
  update VF GGTT PTEs via xe_ggtt_update_vf_ptes(), and return the updated count.
  This removes relay -EOPNOTSUPP errors seen from Windows VF drivers and
  improves guest UI rendering stability.
- Removed the temporary SR-IOV debug noise in xe PF control and PCI SR-IOV
  paths after it served its purpose, and repaired minor syntax leftovers
  from stripping the logs.
*** End Patch}));
